{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfer Learning with Ensemble Method \n",
    "The first part leverages four pretrained models for transfer learning, including VGG16, Xception, InceptionV16, and MobileNetV2. After training several epochs to achieve a certain accuracy rate, an ensemble method is used to average out the predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import relevent packages "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import shutil\n",
    "from PIL import Image\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.backend as K\n",
    "from keras.utils import np_utils\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential, Model, load_model\n",
    "from keras.applications import InceptionV3,VGG16, MobileNetV2, Xception\n",
    "from keras.layers import *\n",
    "from keras.optimizers import *\n",
    "from keras.regularizers import *\n",
    "from keras.callbacks import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Define functions to process data and complie models\n",
    "As the project was accelerated with GPU, the directory was set on Kaggle notebook. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data():\n",
    "    \"\"\"\n",
    "        Assign images to respective foldfers based on their class.\n",
    "    \"\"\"\n",
    "    \n",
    "    os.mkdir(\"/kaggle/working/train_set/\")\n",
    "    train_labels = pd.read_csv(\"../input/final-project-food-recognition-challenge/train_labels.csv\")\n",
    "    \n",
    "    for folder in train_labels[\"label\"].unique():\n",
    "        os.mkdir(\"/kaggle/working/train_set/\"+str(folder))\n",
    "\n",
    "    for index, row in train_labels.iterrows():\n",
    "        shutil.copy(src=\"../input/final-project-food-recognition-challenge/train_set/train_set/\"+row[\"img_name\"], \n",
    "                    dst=\"/kaggle/working/train_set/\"+str(row[\"label\"])+\"/\")\n",
    "\n",
    "        \n",
    "def set_generator():\n",
    "    \"\"\"\n",
    "        Set up image generator for data augmentation.  \n",
    "    \"\"\"\n",
    "\n",
    "    train_datagen = ImageDataGenerator(\n",
    "        rescale=1. / 255,\n",
    "        rotation_range=10,\n",
    "        width_shift_range=0.05,\n",
    "        height_shift_range=0.05,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        channel_shift_range=10,\n",
    "        horizontal_flip=True,\n",
    "        fill_mode='constant',\n",
    "        validation_split=0.2)\n",
    "\n",
    "    \n",
    "    directory = \"/kaggle/working/train_set/\"\n",
    "    img_height, img_width = 255, 255\n",
    "    batch_size = 30\n",
    "\n",
    "    train_generator = train_datagen.flow_from_directory(\n",
    "        directory,\n",
    "        target_size=(img_height, img_width),\n",
    "        batch_size=batch_size,\n",
    "        shuffle = True, \n",
    "        class_mode='categorical',\n",
    "        subset='training')\n",
    "\n",
    "    validation_generator = train_datagen.flow_from_directory(\n",
    "        directory,\n",
    "        target_size=(img_height, img_width),\n",
    "        batch_size=batch_size,\n",
    "        shuffle = True,\n",
    "        class_mode='categorical',\n",
    "        subset='validation')\n",
    "    \n",
    "    nb_train_samples = train_generator.n\n",
    "    nb_validation_samples = validation_generator.n\n",
    "    n_classes = train_generator.num_classes\n",
    "    \n",
    "    return train_generator, validation_generator, nb_train_samples, nb_validation_samples, n_classes\n",
    "\n",
    "\n",
    "def transfer_model(base_model, model_name):\n",
    "    \"\"\"\n",
    "        Freeze the top layers and add some extra layers to train parameters,\n",
    "        and finally compile the model for transfer learning. \n",
    "    \"\"\"\n",
    "    \n",
    "    for layer in base_model.layers[:10]:\n",
    "        layer.trainable = False\n",
    "\n",
    "    x = base_model.output\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Dense(512, activation='relu')(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    predictions = Dense(80, activation='softmax')(x)\n",
    "    model = Model(inputs=base_model.inputs, outputs=predictions)\n",
    "\n",
    "    model.compile(optimizer=SGD(lr=0.0001, momentum=0.9), \n",
    "                  loss='categorical_crossentropy', \n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "def train_model(model, model_name, epoch_num):\n",
    "    \"\"\"\n",
    "        Train the pre-trained model according to the epoches needed.\n",
    "    \"\"\"\n",
    "    \n",
    "    batch_size = 30\n",
    "    checkpointer = ModelCheckpoint(filepath='food_classification_'+ model_name +'.hdf5',\n",
    "                                   verbose=1,\n",
    "                                   save_best_only=True)\n",
    "    \n",
    "    history = model.fit_generator(train_generator,\n",
    "                               steps_per_epoch = nb_train_samples // batch_size,\n",
    "                               validation_data = validation_generator,\n",
    "                               validation_steps = nb_validation_samples // batch_size,\n",
    "                               epochs = epoch_num,\n",
    "                               verbose = 1,\n",
    "                               callbacks = [checkpointer, es]\n",
    "                              )\n",
    "    \n",
    "    outputdir = \"/kaggle/working/\"\n",
    "    model.save(os.path.join(outputdir, f'{model_name}_{epoch_num}.hdf5'))\n",
    "    \n",
    "    return history \n",
    "\n",
    "\n",
    "def predict_labels(model):\n",
    "\n",
    "    test_datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "    batch_size= 30\n",
    "\n",
    "    pred_dir='../input/final-project-food-recognition-challenge/test_set'\n",
    "\n",
    "    test_generator = test_datagen.flow_from_directory(\n",
    "        directory=pred_dir,\n",
    "        color_mode=\"rgb\",\n",
    "        batch_size= batch_size,\n",
    "        class_mode=None,\n",
    "        shuffle=False\n",
    "    )\n",
    "\n",
    "    test_generator.reset()\n",
    "    \n",
    "    pred=model.predict_generator(test_generator,verbose=1, \n",
    "                             steps=7653/batch_size)\n",
    "\n",
    "    predicted_class_indices=np.argmax(pred,axis=1)\n",
    "\n",
    "    labels = (train_generator.class_indices)\n",
    "    labels = dict((v,k) for k,v in labels.items())\n",
    "    predictions = [labels[k] for k in predicted_class_indices]\n",
    "\n",
    "    filenames=test_generator.filenames\n",
    "    results=pd.DataFrame({\"Filename\":filenames,\n",
    "                          \"Predictions\":predictions})\n",
    "\n",
    "    results.Filename = results.Filename.apply(lambda x: x.replace(\"test_set/test_\", \"\").replace(\".jpg\", \"\")).astype(\"int\")\n",
    "    results = results.sort_values(by='Filename')\n",
    "    \n",
    "    return results\n",
    "\n",
    "def plot_accuracy_loss(history):\n",
    "\n",
    "    fig = plt.figure(figsize=(10,5))\n",
    "\n",
    "    # Plot accuracy\n",
    "    plt.subplot(221)\n",
    "    plt.plot(history.history['accuracy'],'bo--', label = \"acc\")\n",
    "    plt.plot(history.history['val_accuracy'], 'ro--', label = \"val_acc\")\n",
    "    plt.title(\"train_acc vs val_acc\")\n",
    "    plt.ylabel(\"accuracy\")\n",
    "    plt.xlabel(\"epochs\")\n",
    "    plt.legend()\n",
    "\n",
    "    # Plot loss function\n",
    "    plt.subplot(222)\n",
    "    plt.plot(history.history['loss'],'bo--', label = \"loss\")\n",
    "    plt.plot(history.history['val_loss'], 'ro--', label = \"val_loss\")\n",
    "    plt.title(\"train_loss vs val_loss\")\n",
    "    plt.ylabel(\"loss\")\n",
    "    plt.xlabel(\"epochs\")\n",
    "\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Load the pretrained models for transfer learning and predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "process_data()\n",
    "train_generator, validation_generator, nb_train_samples, nb_validation_samples, n_classes = set_generator()\n",
    "\n",
    "img_height, img_width = 255, 255\n",
    "batch_size = 30\n",
    "\n",
    "base_model_1 = Xception(weights='imagenet', include_top=False),\n",
    "model_name_1 = \"Xception\"\n",
    "model_1 = transfer_model(base_model_1, model_name_1)\n",
    "hist_1 = train_model(model_1, model_name_1, 50)\n",
    "\n",
    "base_model_2 = MobileNetV2(weights='imagenet', include_top=False)\n",
    "model_name_2 = \"MobileNetV2\"\n",
    "model_2 = transfer_model(base_model_2, model_name_1)\n",
    "hist_2 = train_model(model_2, model_name_2, 70)\n",
    "\n",
    "base_model_3 = VGG16(weights='imagenet', include_top=False)\n",
    "model_name_3 = 'VGG16'\n",
    "model_3 = transfer_model(base_model_3, model_name_3)\n",
    "hist_3 = train_model(model_3, model_name_3, 50)\n",
    "\n",
    "base_model_4 = InceptionV3(weights='imagenet', include_top=False)\n",
    "model_name_4 = 'InceptionV3'\n",
    "model_4 = transfer_model(base_model_4, model_name_4)\n",
    "hist_4 = train_model(model_4, model_name_4, 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Assemble all the transfer learning models for final predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1_path = '../input/inception-best/best_model_food101_InceptionV3_1209.hdf5'\n",
    "model_1 = load_model(model_1_path)\n",
    "model_1 = Model(inputs=model_1.inputs,\n",
    "                outputs=model_1.outputs,\n",
    "                name= model_name_1)\n",
    "\n",
    "model_2_path = '../input/xception-30/Xception_30.h5'\n",
    "model_2 = load_model(model_2_path)\n",
    "model_2 = Model(inputs=model_2.inputs,\n",
    "                outputs=model_2.outputs,\n",
    "                name= model_name_2)\n",
    "\n",
    "model_3_path = '../input/mobilenet-100/MobileNet_100.h5'\n",
    "model_3 = load_model(model_3_path)\n",
    "model_3 = Model(inputs=model_3.inputs,\n",
    "                outputs=model_3.outputs,\n",
    "                name=model_name_3)\n",
    "\n",
    "model_4_path = '../input/vgg-45/VGG_45.h5'\n",
    "model_4 = load_model(model_4_path)\n",
    "model_4 = Model(inputs=model_4.inputs,\n",
    "                outputs=model_4.outputs,\n",
    "                name=model_name_4)\n",
    "\n",
    "models = [model_1, model_2, model_3, model_4]\n",
    "\n",
    "model_input = Input(shape=(img_width, img_height, 3))\n",
    "model_outputs = [model(model_input) for model in models]\n",
    "\n",
    "ensemble_output = Average()(model_outputs) \n",
    "ensemble_model = Model(inputs=model_input, outputs=ensemble_output, name='ensemble')\n",
    "\n",
    "final_pred = predict_labels(ensemble_model)\n",
    "final_pred.to_csv('submission.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
